##Interpreting Digital Discourse: Political Lean Prediction Based on Reddit Posts
This project is a part of the AAI-501 course in the Applied Artificial Intelligence Program at the University of San Diego (USD). 
Project Status: [Completed]
## Installation
To use this project, first clone the repo on your device using the below command:
git clone https://github.com/AAI-501/aai_501_project.git
## Project Introduction
The “Interpreting Digital Discourse: Political Lean Prediction Based on Reddit Posts” project aims to provide an efficient toolset for the political lean classification and  prediction by working with the "Liberals vs Conservatives on Reddit [13000 posts]" dataset from Kaggle (Gajare, 2022). The goal of our research is to identify the most effective approach to perform such a task, while providing context on ethics and the future of classification of the user generated content.
## Contributors
1.	Zain Ali
2.	Ksenia Kold
3.	Arun Kumar Palanisamy
	
## Methods Used
1. Descriptive Statistics
2. Inferential Statistics
3. SVM(Support Vector Machine)  + TfidfVectorizer
4. SVM(Support Vector Machine)  + CountVectorizer
5. SVM(Support Vector Machine)  + Universal Sentence Encoder
6. Naive Bayes + TfidfVectorizer
7. Naive Bayes + CountVectorizer
8. KNN(K- Nearest Neighbors) + TfidfVectorizer
9. KNN(K- Nearest Neighbors)  + CountVectorizer
10. KNN(K- Nearest Neighbors)  + Universal Sentence Encoder
11. Logistic Regression + TfidfVectorizer
12. Logistic Regression + CountVectorizer
13. Logistic Regression + Universal Sentence Encoder
14. Random Forest + TfidfVectorizer
15. Random Forest + CountVectorizer
16. Random Forest + Universal Sentence Encoder
## Technologies
   Python
## Project Description
Data source: [Liberals vs Conservatives on Reddit [13000 posts] (kaggle.com)]
( https://www.kaggle.com/datasets/neelgajare/liberals-vs-conservatives-on-reddit-13000-posts)
Name of the variables: Title, Political Lean, Score, Id, Subreddit, URL, Num of Comments, Text, Date Created, Combined_Text, Cleaned_Text

Number of variables: 11

Size of the dataset: 12854

Used Descriptive Analysis, Histogram, Plots

Used SVM(Support Vector Machine)  + TfidfVectorizer | CountVectorizer | Universal Sentence Encoder, Naive Bayes + TfidfVectorizer | CountVectorizer, KNN(K- Nearest Neighbors) + TfidfVectorizer | CountVectorizer | Universal Sentence Encoder, Logistic Regression + TfidfVectorizer | CountVectorizer | Universal Sentence Encoder, Random Forest + TfidfVectorizer | CountVectorizer | Universal Sentence Encoder
## Acknowledgments
Thank you Andrew Van Benschoten for your support
   








